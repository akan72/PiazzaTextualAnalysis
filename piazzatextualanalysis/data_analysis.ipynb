{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Are students asking conceptual or appllied questions?\n",
    "Which topics are more prevalent? Where is the most confusion?\n",
    "    - Topic Modeling\n",
    "    - Run the same topic model over different intervals of time\n",
    "What do in-person interactions not already tell us? \n",
    "What are areas that need attention in student understanding? \n",
    "    - Concrete evidence of topics where students are struggling\n",
    "Probably don't look at response time\n",
    "What are people afraid of asking about? (Anonymous posts from students)\n",
    "Data:\n",
    "    - Timestamp\n",
    "    - Userid (student or instructor, throw out announcements)\n",
    "    - Question or answer? \n",
    "    - Votes (good question)\n",
    "    - Question Text\n",
    "    \n",
    "    \n",
    "diff values of config?\n",
    "Check status = active\n",
    "transform to get length of upvote_ids\n",
    "\n",
    "Question or Answer? \n",
    "Num votes/good question\n",
    "where does anon equal yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn.decomposition import LatentDirichletAllocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/dataframes/lexokan@live.unc.edu_dataframe_jkws0l0gvcr7it.p',\n",
       " 'data/dataframes/lexokan@live.unc.edu_dataframe_iqv0bsb3p2i3ch.p',\n",
       " 'data/dataframes/lexokan@live.unc.edu_dataframe_jz8ejj1lawb5st.p',\n",
       " 'data/dataframes/lexokan@live.unc.edu_dataframe_j5wwaj87hvu6af.p',\n",
       " 'data/dataframes/lexokan@live.unc.edu_dataframe_jqnyuvgzug4p3.p']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = glob.glob('data/dataframes/*.p')\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = []\n",
    "\n",
    "currentDf = pd.read_pickle(dfs[0])\n",
    "dataList = currentDf[\"text\"].tolist()\n",
    "\n",
    "# Todo: Get rid of numbers in topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('39', 140.95326649585357), ('use', 20.804434752360358), ('assignment', 14.811469185193685), ('object', 12.623352691216247), ('ve', 11.484447599328908), ('know', 10.580758446026328), ('need', 9.459735780301786), ('does', 8.407564104872732), ('check', 8.368665167996351), ('sure', 8.267402817823442)]\n",
      "Topic 1:\n",
      "[('class', 52.301734253785135), ('question', 40.31169459651808), ('answer', 24.063758065243135), ('does', 18.435248452614843), ('method', 17.409193002734842), ('39', 13.111621383861214), ('main', 12.276596965066767), ('quiz', 11.362593864355421), ('java', 11.130682284981855), ('points', 10.196068742687238)]\n",
      "Topic 2:\n",
      "[('office', 38.89782999672165), ('hours', 29.84560599419356), ('today', 13.16277626298716), ('12', 5.219108813006488), ('11', 4.19318727120703), ('final', 3.1594251475206896), ('need', 2.4893905255194224), ('able', 2.2399911704730244), ('getting', 2.23990595344239), ('quiz', 2.2116297853878617)]\n",
      "Topic 3:\n",
      "[('assignment', 26.1379634888312), ('10', 23.282354048839792), ('make', 20.124753085287953), ('credit', 15.550371274906245), ('extra', 15.371531534937624), ('sure', 15.175826942749818), ('just', 15.12046410967574), ('time', 14.51825730157268), ('students', 13.188516662193033), ('class', 10.761225354140091)]\n",
      "Topic 4:\n",
      "[('exam', 32.71058687811864), ('class', 16.852120145928524), ('test', 10.618427405081073), ('need', 9.906244290010434), ('prasun', 8.78876150872023), ('time', 7.918177094128127), ('code', 7.856052389616698), ('message', 7.3762609388164915), ('good', 7.294336388079348), ('late', 6.972093969559085)]\n",
      "Topic 5:\n",
      "[('34', 91.3450418653424), ('object', 16.424846805334013), ('like', 11.915651681275332), ('using', 9.996944760393713), ('case', 6.65172993989717), ('checks', 4.979516031593859), ('check', 4.913296907628943), ('make', 4.505466197176043), ('code', 2.783025592430549), ('mean', 2.092675244862466)]\n",
      "Topic 6:\n",
      "[('server', 23.91504506494236), ('39', 21.48289181269787), ('sakai', 18.569805156430995), ('grading', 17.270382378158914), ('getting', 16.77171010652475), ('error', 15.880919582017068), ('checks', 14.869798723969836), ('grader', 13.77493839377013), ('local', 13.515749991966365), ('points', 13.452316660816296)]\n",
      "Topic 7:\n",
      "[('scene', 20.603205556705582), ('doing', 4.294675469477464), ('assignment', 4.234862153000774), ('understand', 3.5593374632558916), ('code', 2.4767523586469573), ('used', 2.0876062606149106), ('think', 1.6025723796370825), ('grader', 1.2911352130703362), ('instead', 0.9388817719849061), ('just', 0.8841343453792799)]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "def print_topics(model, vectorizer, top_n=10): \n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "\n",
    "\n",
    "num_features = 200\n",
    "tf_vectorizer = CountVectorizer(max_df=.95, min_df=.05, max_features=num_features, stop_words='english')\n",
    "\n",
    "ldaList = []\n",
    "\n",
    "data_samples = dataList\n",
    "tf_data_samples = tf_vectorizer.fit_transform(data_samples) \n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "# Tradeoff between fit and interpretation (possibly between 5-15)\n",
    "num_topics = 8\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, max_iter=100, learning_method='online', learning_offset=10.,random_state=1).fit(tf_data_samples)\n",
    "lda.score(tf_data_samples)\n",
    "\n",
    "ldaList.append(lda)\n",
    "\n",
    "print_topics(lda,tf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud for each topic?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
