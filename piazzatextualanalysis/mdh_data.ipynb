{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "\n",
    "from typing import List, Tuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_raised_hand</th>\n",
       "      <th>time_interaction_began</th>\n",
       "      <th>time_interaction_ended</th>\n",
       "      <th>im_working_on</th>\n",
       "      <th>my_problem_is</th>\n",
       "      <th>ive_tried</th>\n",
       "      <th>teacher_suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-20 20:54:17</td>\n",
       "      <td>2019-09-20 21:26:59</td>\n",
       "      <td>2019-09-20 21:28:53</td>\n",
       "      <td>A3 Novice and Jedi</td>\n",
       "      <td>Not passing jUnits test - things that should w...</td>\n",
       "      <td>everything</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-23 14:13:16</td>\n",
       "      <td>2019-09-23 14:22:47</td>\n",
       "      <td>2019-09-23 14:32:18</td>\n",
       "      <td>a4 novice</td>\n",
       "      <td>How to start</td>\n",
       "      <td>reading read me</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-23 17:35:49</td>\n",
       "      <td>2019-09-23 17:46:27</td>\n",
       "      <td>2019-09-23 18:04:46</td>\n",
       "      <td>A3 Novice Tests</td>\n",
       "      <td>differentiating between the interface name and...</td>\n",
       "      <td>Renaming the classes, but that creates more er...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-23 17:35:50</td>\n",
       "      <td>2019-09-23 17:36:31</td>\n",
       "      <td>2019-09-23 18:14:30</td>\n",
       "      <td>A3 Novice Tests</td>\n",
       "      <td>Having trouble with default methods &amp; Junit</td>\n",
       "      <td>Output good</td>\n",
       "      <td>Go see getWaitTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-23 19:17:07</td>\n",
       "      <td>2019-09-23 19:18:20</td>\n",
       "      <td>2019-09-23 20:19:05</td>\n",
       "      <td>A3 Adept, Novice</td>\n",
       "      <td>Creating a constructor for ShortestWaitDispatcher</td>\n",
       "      <td>creating one myself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_raised_hand time_interaction_began time_interaction_ended  \\\n",
       "0  2019-09-20 20:54:17    2019-09-20 21:26:59    2019-09-20 21:28:53   \n",
       "1  2019-09-23 14:13:16    2019-09-23 14:22:47    2019-09-23 14:32:18   \n",
       "2  2019-09-23 17:35:49    2019-09-23 17:46:27    2019-09-23 18:04:46   \n",
       "3  2019-09-23 17:35:50    2019-09-23 17:36:31    2019-09-23 18:14:30   \n",
       "4  2019-09-23 19:17:07    2019-09-23 19:18:20    2019-09-23 20:19:05   \n",
       "\n",
       "        im_working_on                                      my_problem_is  \\\n",
       "0  A3 Novice and Jedi  Not passing jUnits test - things that should w...   \n",
       "1           a4 novice                                       How to start   \n",
       "2     A3 Novice Tests  differentiating between the interface name and...   \n",
       "3     A3 Novice Tests        Having trouble with default methods & Junit   \n",
       "4    A3 Adept, Novice  Creating a constructor for ShortestWaitDispatcher   \n",
       "\n",
       "                                           ive_tried teacher_suggestions  \n",
       "0                                         everything                 NaN  \n",
       "1                                    reading read me                 NaN  \n",
       "2  Renaming the classes, but that creates more er...                 NaN  \n",
       "3                                        Output good  Go see getWaitTime  \n",
       "4                                creating one myself                 NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/my_digital_hand/mdh_logs.p')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary LDA Functions (c&p from the data_analysis file, thanks alex)\n",
    "def print_topics(model, vectorizer, top_n: int=10)-> List: \n",
    "    \n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        \n",
    "    return [vectorizer.get_feature_names()[i] for i in topic.argsort()[:-top_n-1:-1]]\n",
    "        \n",
    "def lda_operation(data_samples, num_features: int=100, num_topics: int=3)-> Tuple: \n",
    "    \n",
    "    tf_vectorizer = CountVectorizer(max_df=.50, min_df=.0, max_features=num_features, stop_words='english', token_pattern=u'(?ui)\\\\b\\\\w\\w*[a-z]+\\\\w*\\\\b')\n",
    "    \n",
    "    tf_data_samples = tf_vectorizer.fit_transform(data_samples) \n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, max_iter=10, learning_method='online', learning_offset=10.,random_state=1).fit(tf_data_samples)\n",
    "    lda.score(tf_data_samples)\n",
    "\n",
    "    return lda, tf_vectorizer\n",
    "\n",
    "def save_topics(model, vectorizer, top_n: int=10)-> List:\n",
    "\n",
    "    words_per_topic = []\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        words = [vectorizer.get_feature_names()[i] for i in topic.argsort()[:-top_n-1:-1]]\n",
    "        words_per_topic.append(words)\n",
    "        \n",
    "    return words_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('code', 67.84499957526695), ('output', 48.784141632696006), ('questions', 44.822284003521155), ('array', 41.99147167387723), ('help', 36.87840105609537), ('need', 34.804845995362925), ('sure', 34.10421034421704), ('understand', 33.54866581938843), ('win', 32.81901241819195), ('spot', 31.159635087920602)]\n",
      "Topic 1:\n",
      "[('don', 86.1790858765925), ('method', 76.64322522353764), ('know', 74.82295327793463), ('test', 74.23208421833621), ('work', 59.97492076923204), ('gradescope', 38.19694906956188), ('start', 37.925554188997644), ('jedi', 36.45104707169026), ('won', 33.880539586061325), ('pass', 32.961003350827355)]\n",
      "Topic 2:\n",
      "[('tests', 165.85982373015204), ('failing', 93.61957394548692), ('junit', 67.88146710526038), ('understanding', 64.12770316345467), ('methods', 62.960723297177985), ('paint', 47.315580643559684), ('adept', 46.72947138889848), ('having', 39.08018184982573), ('novice', 38.112137180156644), ('working', 37.04161641569801)]\n"
     ]
    }
   ],
   "source": [
    "lda_output = []\n",
    "data_list = df['my_problem_is'].tolist()\n",
    "lda_output.append(lda_operation(data_list))\n",
    "    \n",
    "# Save all of the words found by the topic model for each class\n",
    "for output in lda_output:\n",
    "    print_topics(*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
