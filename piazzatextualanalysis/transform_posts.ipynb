{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 4,
>>>>>>> initial commit for merge
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 15,
>>>>>>> initial commit for merge
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all posts within the data directory\n",
    "posts = glob.glob('data/posts/*.p')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-45d3f72a3b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<[^<]+?>|\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mvalidate_instructor_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Reorder the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-45d3f72a3b1d>\u001b[0m in \u001b[0;36mvalidate_instructor_counts\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mis_student_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_student'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mis_student_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mis_instructor_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mis_student_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mis_instructor_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
>>>>>>> initial commit for merge
   "source": [
    "def validate_instructor_counts(df):\n",
    "    '''\n",
    "    Confirm that a post is either tagged as `instructor` or `student` but not both.\n",
    "    '''\n",
    "    is_instructor_counts = df['is_instructor'].value_counts()\n",
    "    is_student_counts = df['is_student'].value_counts()\n",
    "\n",
    "    assert is_student_counts[0] == is_instructor_counts[1]\n",
    "    assert is_student_counts[1] == is_instructor_counts[0]\n",
    "    \n",
    "def num_nested_dicts(d: dict, column: str):\n",
    "    '''\n",
    "    Fuction that will send the number of nested dictionaries with a specified key back to the caller.\n",
    "    Used with len(list(.)) later on in the data pipeline.\n",
    "    '''\n",
    "    if column in d:\n",
    "        yield d['created']\n",
    "    for k in d:\n",
    "        if isinstance(d[k], list) and k == 'column':\n",
    "            for i in d[k]:\n",
    "                for j in num_nested_dicts(i):\n",
    "                    yield j\n",
    "\n",
    "# Iterate over all posts within a class\n",
    "for fp in posts:\n",
    "    # Load each post into a DataFrame and store its networkid\n",
    "    df = pd.DataFrame(pickle.load(open(fp, \"rb\")))\n",
    "    network_id = re.search(\"posts_(.*).p\", fp).group(1)\n",
    "    \n",
    "    # Compute different metrics about the class\n",
    "    df['created'] = pd.to_datetime(df['created'])\n",
    "    df['num_revisions'] = df['history'].apply(lambda x: len(x))\n",
    "    df['subject'] = df['history'].apply(lambda x: x[0]['subject'])\n",
    "    df['is_student'] = df['tags'].apply(lambda x: 'student' in x)\n",
    "    df['is_instructor'] = df['tags'].apply(lambda x: 'instructor-note' in x)\n",
    "    df['is_announcement'] = df['config'].apply(lambda x: 1 if 'is_announcement' in x else 0)\n",
    "    df['num_children'] = df['children'].apply(lambda x: len(list(num_nested_dicts(x[0], 'children'))) if len(x) > 0 else 0)\n",
    "\n",
    "    # Remove HTML from text column\n",
    "    df['text'] = df['history'].apply(lambda x: re.sub('<[^<]+?>|\\n', ' ', x[0]['content']))\n",
    "    \n",
    "    validate_instructor_counts(df)\n",
    "    \n",
    "    # Reorder the columns\n",
    "    df = df[['id', 'created', 'type', 'folders', 'tags', 'is_announcement', 'history', 'children', 'tag_good', 'is_student', 'no_answer', 'num_children', 'num_favorites', 'num_revisions', 'unique_views', 'subject','text']]\n",
    "    \n",
    "    # Pickle the transformed DataFrame and save\n",
    "    with open(f\"data/dataframes/{os.environ['PIAZZA_EMAIL']}_dataframe_{network_id}.p\", 'wb') as f:\n",
    "            pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> initial commit for merge
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.4"
=======
   "version": "3.7.3"
>>>>>>> initial commit for merge
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
