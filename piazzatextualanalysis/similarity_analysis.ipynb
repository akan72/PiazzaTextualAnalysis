{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from gensim import corpora, models, similarities\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posts & post titles from df --> lists of strings\n",
    "#Each string in list is the full text of the post or title, will be parsed later\n",
    "\n",
    "dfs = glob.glob('data/dataframes/*.p')\n",
    "frames = []\n",
    "for cdf in dfs:\n",
    "    frames.append(pd.read_pickle(cdf))\n",
    "df = pd.concat(frames)\n",
    "df = df[df.is_student == True]\n",
    "dataList = df[\"text\"].tolist()\n",
    "subjectList = df[\"subject\"].tolist()\n",
    "z = list(zip(dataList, subjectList))\n",
    "\n",
    "#Randomizing order if later want to split into training and test inputs\n",
    "# random.shuffle(z)\n",
    "# dataList[:], subjectList[:] = zip(*z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://medium.com/better-programming/introduction-to-gensim-calculating-text-similarity-9e8b55de342d\n",
    "\n",
    "texts = dataList\n",
    "texts = [jieba.lcut(text) for text in texts] #tokenize text of post, turns string into list of substrings\n",
    "dictionary = corpora.Dictionary(texts) #make dictionary where postId --> list of substrings\n",
    "feature_cnt = len(dictionary.token2id) #get doc count for later\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] #corpus is bag of words from docs in dictionary\n",
    "tfidf = models.TfidfModel(corpus) #construct tf-idf model on corpus\n",
    "\n",
    "#repeat the above but for post titles\n",
    "subjects = subjectList\n",
    "subjects = [jieba.lcut(subject) for subject in subjects]\n",
    "subDict = corpora.Dictionary(subjects)\n",
    "sub_fc = len(subDict.token2id)\n",
    "subCorpus = [subDict.doc2bow(subject) for subject in subjects]\n",
    "subTfidf = models.TfidfModel(subCorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These posts might be similar to what you're looking for: \n",
      "\n",
      "keyword is similar to text1744: 0.37\n",
      " Can someone explain how to put the Junit tests into eclipse? I&#39;m having trouble getting them to run and i don&#39;t know if I&#39;m doing something completely wrong - I made sure to add the junit test to the classpath and made sure the a6 project is linked to it as well. any help would be appreciated! also big thank you to the people who shared their junit test code on piazza! \n",
      "\n",
      "\n",
      "keyword is similar to text1968: 0.62\n",
      " I followed the a3 grader steps to add the Junit tests to work for a4, and a4 is in the class path, but the line that imports a4 is giving me an error. How do I fix this?      Edit: This is the error message that pops up. I have tried hovering over and manually clicking &#34;fix project setup&#34; as well.       Screen_Shot_20190928_at_2.48.20_PM.png  \n",
      "\n",
      "\n",
      "keyword is similar to text1925: 0.28\n",
      " I pass jedi code in junit tests but not on the autograder? Is there a fix? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### If you want to input in the command line\n",
    "# print(\"Title:\")\n",
    "# subKw = input()\n",
    "# print(\"Post:\")\n",
    "# keyword = input()\n",
    "#####\n",
    "\n",
    "### Sample inputs for demo\n",
    "keyword = \"I used the instructions on Sakai for adding the junit tests but I'm still getting an error. Does anyone know how to fix this?\"\n",
    "subKw = \"Error adding Junit tests\"\n",
    "# keyword = \"Is there going to be an curve on the midterm or are our gradescope scores the final grade?\"\n",
    "# subKw = \"Exam grades\"\n",
    "# keyword = \"Will the questions on the final be similar to the types of questions on the midterm?\"\n",
    "# subKw = \"Final exam format\"\n",
    "# keyword = \"For ShortButFairDispatcher, I'm not sure what it's asking. How are we supposed to determine which driver is the closest if the closest driver was in the last 5?\"\n",
    "# subKw = \"ShortestButFairDispatcher\"\n",
    "#####\n",
    "\n",
    "\n",
    "#source: https://medium.com/better-programming/introduction-to-gensim-calculating-text-similarity-9e8b55de342d\n",
    "kw_vector = dictionary.doc2bow(jieba.lcut(keyword)) #cuts input phrase into sparse vector\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt) #calculates vector similarity\n",
    "sim = index[tfidf[kw_vector]] #gets similarity score of keyword vector to each item in corpus\n",
    "\n",
    "#repeats above block for post titles\n",
    "subKw_vector = subDict.doc2bow(jieba.lcut(subKw))\n",
    "subIndex = similarities.SparseMatrixSimilarity(subTfidf[subCorpus], num_features = sub_fc)\n",
    "subSim = subIndex[subTfidf[subKw_vector]]     \n",
    "\n",
    "#prints out similar posts from each of 3 formulas\n",
    "print(\"These posts might be similar to what you're looking for: \\n\")\n",
    "\n",
    "for i in range(len(sim)):\n",
    "    if sim[i]*1+subSim[i]*0.5 > balanced: #\n",
    "        balanced = sim[i]*1+subSim[i]*0.5\n",
    "        balanced_id = i\n",
    "    if sim[i]*1+subSim[i]*1 > sub_bias:\n",
    "        sub_bias = sim[i]*1+subSim[i]*1\n",
    "        sub_bias_id = i   \n",
    "    if sim[i]*1+subSim[i]*0.1 > post_bias:\n",
    "        post_bias = sim[i]*1+subSim[i]*0.1\n",
    "        post_bias_id = i  \n",
    "\n",
    "print('keyword is similar to text%d: %.2f' % (balanced_id, balanced))\n",
    "print(dataList[balanced_id])\n",
    "print(\"\\n\")\n",
    "    \n",
    "\n",
    "print('keyword is similar to text%d: %.2f' % (sub_bias_id, sub_bias))\n",
    "print(dataList[sub_bias_id])\n",
    "print(\"\\n\")\n",
    "      \n",
    "        \n",
    "print('keyword is similar to text%d: %.2f' % (post_bias_id, post_bias))\n",
    "print(dataList[post_bias_id])\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
