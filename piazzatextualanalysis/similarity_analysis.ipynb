{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from gensim import corpora, models, similarities\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = glob.glob('data/dataframes/*.p')\n",
    "frames = []\n",
    "for cdf in dfs:\n",
    "    frames.append(pd.read_pickle(cdf))\n",
    "df = pd.concat(frames)\n",
    "df = df[df.is_student == True]\n",
    "dataList = df[\"text\"].tolist()\n",
    "subjectList = df[\"subject\"].tolist()\n",
    "z = list(zip(dataList, subjectList))\n",
    "\n",
    "random.shuffle(z)\n",
    "dataList[:], subjectList[:] = zip(*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataList\n",
    "texts = [jieba.lcut(text) for text in texts]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "feature_cnt = len(dictionary.token2id)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "tfidf = models.TfidfModel(corpus) \n",
    "\n",
    "subjects = subjectList\n",
    "subjects = [jieba.lcut(subject) for subject in subjects]\n",
    "subDict = corpora.Dictionary(subjects)\n",
    "sub_fc = len(subDict.token2id)\n",
    "subCorpus = [subDict.doc2bow(subject) for subject in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These posts might be similar to what you're looking for: \n",
      "\n",
      "keyword is similar to text2176: 0.49\n",
      " I followed the a3 grader steps to add the Junit tests to work for a4, and a4 is in the class path, but the line that imports a4 is giving me an error. How do I fix this?      Edit: This is the error message that pops up. I have tried hovering over and manually clicking &#34;fix project setup&#34; as well.       Screen_Shot_20190928_at_2.48.20_PM.png  \n",
      "\n",
      "\n",
      "keyword is similar to text2176: 0.89\n",
      " I followed the a3 grader steps to add the Junit tests to work for a4, and a4 is in the class path, but the line that imports a4 is giving me an error. How do I fix this?      Edit: This is the error message that pops up. I have tried hovering over and manually clicking &#34;fix project setup&#34; as well.       Screen_Shot_20190928_at_2.48.20_PM.png  \n",
      "\n",
      "\n",
      "keyword is similar to text2176: 0.27\n",
      " PA.load(\"/dashboard/get_familiar\", null, function(data){ $('#' + 'questionText').html(data);}); \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"Title:\")\n",
    "# subKw = input()\n",
    "# print(\"Post:\")\n",
    "# keyword = input()\n",
    "keyword = \"I followed the instructions for adding the junit tests but I am still getting an error. Does anyone know what I'm doing wrong?\"\n",
    "subKw = \"Junit test not working\"\n",
    "\n",
    "kw_vector = dictionary.doc2bow(jieba.lcut(keyword))\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)\n",
    "sim = index[tfidf[kw_vector]]\n",
    "\n",
    "subTfidf = models.TfidfModel(subCorpus)\n",
    "subKw_vector = subDict.doc2bow(jieba.lcut(subKw))\n",
    "subIndex = similarities.SparseMatrixSimilarity(subTfidf[subCorpus], num_features = sub_fc)\n",
    "subSim = subIndex[subTfidf[subKw_vector]]     \n",
    "\n",
    "equal = 0\n",
    "equal_id = 0\n",
    "sub_bias = 0\n",
    "sub_bias_id = 0\n",
    "post_bias = 0\n",
    "post_bias_id = 0\n",
    "\n",
    "print(\"These posts might be similar to what you're looking for: \\n\")\n",
    "\n",
    "for i in range(len(sim)):\n",
    "    if sim[i]*1+subSim[i]*0.5 > equal:\n",
    "        equal = sim[i]*1+subSim[i]*0.5\n",
    "        equal_id = i\n",
    "\n",
    "print('keyword is similar to text%d: %.2f' % (i, equal))\n",
    "print(dataList[equal_id])\n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(sim)):\n",
    "    if sim[i]*1+subSim[i]*1 > sub_bias:\n",
    "        sub_bias = sim[i]*1+subSim[i]*1\n",
    "        sub_bias_id = i   \n",
    "\n",
    "print('keyword is similar to text%d: %.2f' % (i, sub_bias))\n",
    "print(dataList[sub_bias_id])\n",
    "print(\"\\n\")\n",
    " \n",
    "for i in range(len(sim)):\n",
    "    if sim[i]*1+subSim[i]*0 > post_bias:\n",
    "        post_bias = sim[i]*1+subSim[i]*0.1\n",
    "        post_bias_id = i        \n",
    "        \n",
    "print('keyword is similar to text%d: %.2f' % (i, post_bias))\n",
    "print(dataList[post_bias_id])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
